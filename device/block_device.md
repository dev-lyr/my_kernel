# 一 概述:
## (1)相关概念:
- **扇区(sector, 也称设备快)**:块设备的每次数据传输都是一组称为扇区的相邻字节, 大部分磁盘设备的扇区大小为512字节, 扇区是数据传输的基本单元, 硬盘控制器将磁盘看作一大组扇区.
- **块(block, 也称文件块/I/O块)**: 是VFS和文件系统传送数据的基本单元, 块对于一个或多个扇区, 块的大小是2的幂, 是扇区大小的整数倍.块设备的大小不唯一, 创建磁盘文件系统时可以选择合适的块大小.
- **缓冲区**: 当块被调入内存时(读或写), 它存储在一个缓冲区中, 每个缓冲区与一个块对应, 块的大小不能超过一个页面, 因此一个页可以容纳一个或多个内存中的块.
- **请求队列**: 每个块设备驱动程序都维持自己的请求队列, 它包含设备待处理的请求链表, 在每个请求队列单独执行I/O调度, 可以提高性能, 请求队列使用request_queue结构体表示, 单个请求使用request
结构体表示.

## (2)块设备处理流程:
- 系统调用例如read调用合适的VFS函数.
- VFS决定是从磁盘告诉缓存中读取还是访问磁盘上的数据, 若访问磁盘数据向下走.
- 内核依赖**映射层(mapping layer)**:内核确定文件所在文件系统的块大小, 并计算请求数据的长度; 接下来调用具体文件系统的函数, 访问文件的磁盘节点, 根据逻辑块号(由于文件可能存放在磁盘上不连续块中, 因此需要逻辑块号)计算中数据在磁盘位置.
- 然后内核通过**通用(general block layer)层**启动IO操作来传递所请求的数据, 每个IO操作只针对磁盘上一组连续的块, 由于请求的数据不必位于连续块中, 因此通用层可能会启动多个IO操作. 通用块层为所有块设备提供一个抽象视图, 隐藏硬件块设备间差异.
- 通用层下是**IO调度程序**, IO调度程序根据预先定义的内核策略来将IO数据传送请求进行归类, 主要是把物理上相邻的数据请求聚集在一起.
- 最后块设备驱动程序向磁盘控制器的硬件接口发送合适的命令, 从而进行实际的数据传送和读取, I/O操作完成后**产生I/O中断**.

## (3)struct block_device(include/linux/fs.h):
- 备注: 每个块设备文件都由block_device结构的描述符来表示.

## (4)相关文件:
- fs/block_dev.c
- include/linux/fs.h

# 二 通用块层:
## (1)概述:
- 通用块层是一个内核组件, 处理来自系统中所有块设备发出的请求. 
- 通用块层使用bio结构表示块设备的I/O操作.

## (2)bio结构(include/linux/blk_types.h):
- bi_opf: 操作类型,参考enum req_op, 读(REQ_OP_READ), 写(REQ_OP_WRITE).
- bi_next: 连接到请求队列中下一个bio.
- bio_end_io_t * bi_end_io: bio的I/O结束时调用的方法.
- bi_private
- bi_destructor: 释放bio时调用的析构方法.

## (3)提交I/O请求:
- bio_alloc(include/linux/bio.h): 分配一个新的bio描述符并初始化.
- submit_io或submit_io_wait: 提交bio请求, 底层都调用generic_make_request.

## (4)generic_make_request:
- 向块设备提交I/O请求, 传递一个struct &bio描述该I/O需要做的事情.
- 不返回任何状态, 请求的成功和失败通过bio->bi_end_io函数来异步传递.
- 调用请求队列(request_queue)的make_request_fn将bio放入请求队列, 返回.

# 三 I/O调度程序.
## (1)概述:
- I/O调度程序将磁盘I/O资源分配给系统中所有挂起的I/O请求, I/O调度程序将请求队列中挂起的请求进行合并和排序, 从而极大提高块设备的性能.
- 合并: 将两个或多个请求结合成一个新请求, 减少系统开销和磁盘寻址次数.
- 排序: 整个请求序列按扇区增长方向有序排序, 保持磁盘头以直线方向移动, 缩短了所有请求的磁盘寻址时间.
- **内核组件读/写一些磁盘数据时, 实际上只是创建了一个块设备请求, 并不是请求立即被满足, I/O操作只是被调度, 执行会向后推迟**.

## (2)I/O调度算法(又称电梯算法):
- Linux2.6提供四种调度算法: 预期算法(Anticipatory,as), 最后期限(Deadline), 完全公平队列(Complete Fairness Queue, CFQ), Noop(No Operation)算法.
- 在内核引导是通过内核参数:elevator进行设置, 默认是预期算法;也可以在运行时通过/sys/block/xxx/queue/scheduler文件中指定某特定块设备的调度算法.
- 每个请求队列对应一个struct elevator_queue *elevator表示相关的调度算法.

## (3)请求队列(struct request_queue, include/linux/blkdev.h):
- 每个请求队列都有一个允许处理的最大请求数, request_queue结构的nr_requests表示每个数据传输方向所允许处理的最大请求数, 默认是至少128个读请求和写请求.
- 若待处理读(写)请求数超过nr_request, 则通过queue_flags字段将队列标记已满, 视图把请求放入队列中的阻塞进程会被放到request_list结构表示的等待队列中睡眠.
- 一个填满请求队列对系统性能有影响, 会强制很多进程去睡眠以等待I/O数据传送完成. 因此若给定方向待处理请求数超过nr_congestion_on字段的值(默认113), 则内核认为该队列是拥塞, 并试图降低新请求的创建速度.
- request_fn_proc *request_fn: 实现驱动程序调用程序的入口方法.

## (4)请求(struct request, include/linux/blkdev.h):
- 每个请求包含一个或对个bio结构, 每个块设备的待处理请求都用一个请求描述符表示.

# 四 块设备驱动程序:
## (1)概述:
- 块设备驱动程序是Linux块子系统中最底层组件, 他们从I/O调度程序中获得请求, 然后按照要求处理这些请求.

## (2)策略例程(strategy route):
- 是一个函数或一组函数, 就是请求队列描述符中的request_fn方法, 与硬件块设备之间相互作用来处理请求队列中的需求. 
- 例如:scsi的scsi_request_fn, for循环直至请求队列为空或不能够接收更多请求.



